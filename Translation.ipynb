{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPOq5JE3ahhT7dn9u4r8QXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akr-25/Language-Translation/blob/main/Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# English to German Translation model"
      ],
      "metadata": {
        "id": "bbX6kKutGHYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "BzAxwb0dGWqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -c https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxH0LclLG9EJ",
        "outputId": "edd07087-d66b-4b09-c0d5-d173ebd820b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-12 06:35:26--  https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/master/intro-to-pytorch/helper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2813 (2.7K) [text/plain]\n",
            "Saving to: ‘helper.py’\n",
            "\n",
            "helper.py           100%[===================>]   2.75K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-07-12 06:35:26 (38.4 MB/s) - ‘helper.py’ saved [2813/2813]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cXbN2-DG9JcZ"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "import helper\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout, LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0tJLw1X9cNS",
        "outputId": "aae4a6d7-40fd-4883-be0e-2302db0063b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 1226259950617150990\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14465892352\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 7471803164431816584\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading WMT14.en-de dataset"
      ],
      "metadata": {
        "id": "2B3xoJZ1GP8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data && cd data && mkdir vocab && mkdir train && mkdir test"
      ],
      "metadata": {
        "id": "2k1w-zaEK5em"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd data/train && curl -o train.en.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/train.en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctil3zZ9-ikp",
        "outputId": "b8ebdc60-a10e-41f9-a791-164626f1361d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  615M  100  615M    0     0  15.2M      0  0:00:40  0:00:40 --:--:-- 17.2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd data/train && curl -o train.de.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/train.de"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDfq5oWlBA9a",
        "outputId": "6b74759c-a71f-4735-d08e-977372445f6a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  684M  100  684M    0     0  15.5M      0  0:00:44  0:00:44 --:--:-- 17.1M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./data/train/train.de.txt\") as myfile:\n",
        "    headD = [next(myfile) for x in range(5)]\n",
        "\n",
        "with open(\"./data/train/train.en.txt\") as engFile:\n",
        "    headE = [next(engFile) for x in range(5)]\n",
        "\n",
        "for idx in range(5):\n",
        "  print(headD[idx])\n",
        "  print(headE[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx09E_IXAHE7",
        "outputId": "45d13ba0-a13c-44c8-cb7a-825ae1d0d2e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iron cement ist eine gebrauchs ##AT##-##AT## fertige Paste , die mit einem Spachtel oder den Fingern als Hohlkehle in die Formecken ( Winkel ) der Stahlguss -Kokille aufgetragen wird .\n",
            "\n",
            "iron cement is a ready for use paste which is laid as a fillet by putty knife or finger in the mould edges ( corners ) of the steel ingot mould .\n",
            "\n",
            "Nach der Aushärtung schützt iron cement die Kokille gegen den heissen , abrasiven Stahlguss .\n",
            "\n",
            "iron cement protects the ingot against the hot , abrasive steel casting process .\n",
            "\n",
            "feuerfester Reparaturkitt für Feuerungsanlagen , Öfen , offene Feuerstellen etc.\n",
            "\n",
            "a fire restant repair cement for fire places , ovens , open fireplaces etc .\n",
            "\n",
            "Der Bau und die Reparatur der Autostraßen ...\n",
            "\n",
            "Construction and repair of highways and ...\n",
            "\n",
            "die Mitteilungen sollen den geschäftlichen kommerziellen Charakter tragen .\n",
            "\n",
            "An announcement must be commercial character .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  e.g., \"rich-text format\" --> rich ##AT##-##AT## text format."
      ],
      "metadata": {
        "id": "RFnKbnCBD1BY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd data/test && curl -o newstest2012.en.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2012.en\n",
        "!cd data/test && curl -o newstest2012.de.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2012.de\n",
        "!cd data/test && curl -o newstest2013.en.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2013.en\n",
        "!cd data/test && curl -o newstest2013.de.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2013.de\n",
        "!cd data/test && curl -o newstest2014.en.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2014.en\n",
        "!cd data/test && curl -o newstest2014.de.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2014.de\n",
        "!cd data/test && curl -o newstest2015.en.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2015.en\n",
        "!cd data/test && curl -o newstest2015.de.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/newstest2015.de"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUxTEUmmCH9E",
        "outputId": "a563b786-122a-4009-df9b-e7ea8d2f2210"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  396k  100  396k    0     0   187k      0  0:00:02  0:00:02 --:--:--  187k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  459k  100  459k    0     0   205k      0  0:00:02  0:00:02 --:--:--  205k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  346k  100  346k    0     0   168k      0  0:00:02  0:00:02 --:--:--  168k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  395k  100  395k    0     0   174k      0  0:00:02  0:00:02 --:--:--  174k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  345k  100  345k    0     0   166k      0  0:00:02  0:00:02 --:--:--  166k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  377k  100  377k    0     0   182k      0  0:00:02  0:00:02 --:--:--  182k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  252k  100  252k    0     0   131k      0  0:00:01  0:00:01 --:--:--  131k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  277k  100  277k    0     0   134k      0  0:00:02  0:00:02 --:--:--  134k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd data/vocab && curl -o vocab.50K.en.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.en\n",
        "!cd data/vocab && curl -o vocab.50K.de.txt https://nlp.stanford.edu/projects/nmt/data/wmt14.en-de/vocab.50K.de"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amWgf37cCtDk",
        "outputId": "afd77b67-4e2e-4fd8-c3b2-3fe89d3ca156"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  394k  100  394k    0     0   191k      0  0:00:02  0:00:02 --:--:--  191k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  493k  100  493k    0     0   220k      0  0:00:02  0:00:02 --:--:--  220k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./data/vocab/vocab.50K.de.txt\") as myfile:\n",
        "    headD = [next(myfile) for x in range(5)]\n",
        "\n",
        "with open(\"./data/vocab/vocab.50K.en.txt\") as engFile:\n",
        "    headE = [next(engFile) for x in range(5)]\n",
        "\n",
        "for idx in range(5):\n",
        "  print(headD[idx])\n",
        "  print(headE[idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrSjTNCMDZNb",
        "outputId": "2c18f1c0-1dac-4030-c9ac-cd375e377b37"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<unk>\n",
            "\n",
            "<unk>\n",
            "\n",
            "<s>\n",
            "\n",
            "<s>\n",
            "\n",
            "</s>\n",
            "\n",
            "</s>\n",
            "\n",
            ",\n",
            "\n",
            "the\n",
            "\n",
            ".\n",
            "\n",
            ",\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O_RHoVh7GitC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences = []\n",
        "german_sentences = []\n",
        "\n",
        "with open('./data/train/train.en.txt') as eng:\n",
        "  english_sentences = [next(eng) for x in range(1000)]\n",
        "\n",
        "with open('./data/train/train.de.txt') as de:\n",
        "  german_sentences = [next(de) for x in range(1000)]"
      ],
      "metadata": {
        "id": "rH9Xji5eDlcg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(english_sentences))\n",
        "print(len(german_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypU6ufV8GrBz",
        "outputId": "2f93b083-021b-46a2-9a79-7f3ed5a7bea7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(english_sentences[i])\n",
        "  print(german_sentences[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYohrN_SJJaz",
        "outputId": "273d0f67-1f66-4b5b-ebd6-d422a35281d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iron cement is a ready for use paste which is laid as a fillet by putty knife or finger in the mould edges ( corners ) of the steel ingot mould .\n",
            "\n",
            "iron cement ist eine gebrauchs ##AT##-##AT## fertige Paste , die mit einem Spachtel oder den Fingern als Hohlkehle in die Formecken ( Winkel ) der Stahlguss -Kokille aufgetragen wird .\n",
            "\n",
            "iron cement protects the ingot against the hot , abrasive steel casting process .\n",
            "\n",
            "Nach der Aushärtung schützt iron cement die Kokille gegen den heissen , abrasiven Stahlguss .\n",
            "\n",
            "a fire restant repair cement for fire places , ovens , open fireplaces etc .\n",
            "\n",
            "feuerfester Reparaturkitt für Feuerungsanlagen , Öfen , offene Feuerstellen etc.\n",
            "\n",
            "Construction and repair of highways and ...\n",
            "\n",
            "Der Bau und die Reparatur der Autostraßen ...\n",
            "\n",
            "An announcement must be commercial character .\n",
            "\n",
            "die Mitteilungen sollen den geschäftlichen kommerziellen Charakter tragen .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
        "german_words_counter = collections.Counter([word for sentence in german_sentences for word in sentence.split()])\n",
        "\n",
        "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
        "print('{} unique English words.'.format(len(english_words_counter)))\n",
        "print('10 Most common words in the English dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
        "print()\n",
        "print('{} german words.'.format(len([word for sentence in german_sentences for word in sentence.split()])))\n",
        "print('{} unique german words.'.format(len(german_words_counter)))\n",
        "print('10 Most common words in the german dataset:')\n",
        "print('\"' + '\" \"'.join(list(zip(*german_words_counter.most_common(10)))[0]) + '\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Kw9EkCMKwk3",
        "outputId": "ea6a2778-293e-4e4c-ea04-78b8a9147108"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26089 English words.\n",
            "4695 unique English words.\n",
            "10 Most common words in the English dataset:\n",
            "\",\" \"the\" \".\" \"of\" \"and\" \"a\" \"to\" \"in\" \"is\" \"for\"\n",
            "\n",
            "24903 german words.\n",
            "5895 unique german words.\n",
            "10 Most common words in the german dataset:\n",
            "\",\" \".\" \"und\" \"der\" \"die\" \"in\" \"##AT##-##AT##\" \"ist\" \"den\" \"von\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(x):\n",
        "    \"\"\"\n",
        "    Tokenize x\n",
        "    :param x: List of sentences/strings to be tokenized\n",
        "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(x)\n",
        "    return tokenizer.texts_to_sequences(x), tokenizer\n",
        "\n",
        "# Tokenize Example output\n",
        "text_sentences = [\n",
        "    'The quick brown fox jumps over the lazy dog .',\n",
        "    'By Jove , my quick study of lexicography won a prize .',\n",
        "    'This is a short sentence .']\n",
        "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
        "print(text_tokenizer.word_index)\n",
        "print()\n",
        "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(sent))\n",
        "    print('  Output: {}'.format(token_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl093AS5Nkgz",
        "outputId": "63aaea5d-2fe7-4da4-81de-166363b52752"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
            "\n",
            "Sequence 1 in x\n",
            "  Input:  The quick brown fox jumps over the lazy dog .\n",
            "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
            "Sequence 2 in x\n",
            "  Input:  By Jove , my quick study of lexicography won a prize .\n",
            "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
            "Sequence 3 in x\n",
            "  Input:  This is a short sentence .\n",
            "  Output: [18, 19, 3, 20, 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(x, length=None):\n",
        "    \"\"\"\n",
        "    Pad x\n",
        "    :param x: List of sequences.\n",
        "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
        "    :return: Padded numpy array of sequences\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "    return pad_sequences(x, maxlen=length, padding='post')\n",
        "\n",
        "# Pad Tokenized output\n",
        "test_pad = pad(text_tokenized)\n",
        "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
        "    print('Sequence {} in x'.format(sample_i + 1))\n",
        "    print('  Input:  {}'.format(np.array(token_sent)))\n",
        "    print('  Output: {}'.format(pad_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuKfJzKmP63O",
        "outputId": "20d00267-5435-4dd5-8966-94083c7cf37a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence 1 in x\n",
            "  Input:  [1 2 4 5 6 7 1 8 9]\n",
            "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
            "Sequence 2 in x\n",
            "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
            "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
            "Sequence 3 in x\n",
            "  Input:  [18 19  3 20 21]\n",
            "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(x, y):\n",
        "    \"\"\"\n",
        "    Preprocess x and y\n",
        "    :param x: Feature List of sentences\n",
        "    :param y: Label List of sentences\n",
        "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
        "    \"\"\"\n",
        "    preprocess_x, x_tk = tokenize(x)\n",
        "    preprocess_y, y_tk = tokenize(y)\n",
        "\n",
        "    preprocess_x = pad(preprocess_x)\n",
        "    preprocess_y = pad(preprocess_y)\n",
        "\n",
        "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
        "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
        "\n",
        "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
        "\n",
        "preproc_english_sentences, preproc_german_sentences, english_tokenizer, german_tokenizer =\\\n",
        "    preprocess(english_sentences, german_sentences)\n",
        "    \n",
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_german_sequence_length = preproc_german_sentences.shape[1]\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "german_vocab_size = len(german_tokenizer.word_index)\n",
        "\n",
        "print('Data Preprocessed')\n",
        "print(\"Max English sentence length:\", max_english_sequence_length)\n",
        "print(\"Max german sentence length:\", max_german_sequence_length)\n",
        "print(\"English vocabulary size:\", english_vocab_size)\n",
        "print(\"german vocabulary size:\", german_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXkdvcw_QAh5",
        "outputId": "81e1aec3-bb05-4925-ed30-c7fa1d6e31cb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preprocessed\n",
            "Max English sentence length: 88\n",
            "Max german sentence length: 91\n",
            "English vocabulary size: 4180\n",
            "german vocabulary size: 5439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def logits_to_text(logits, tokenizer):\n",
        "    \"\"\"\n",
        "    Turn logits from a neural network into text using the tokenizer\n",
        "    :param logits: Logits from a neural network\n",
        "    :param tokenizer: Keras Tokenizer fit on the labels\n",
        "    :return: String that represents the text of the logits\n",
        "    \"\"\"\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
        "\n",
        "print('`logits_to_text` function loaded.')"
      ],
      "metadata": {
        "id": "C-kkTYbOR5zo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe15cb7e-48cb-44d2-e189-6efcc9f201b7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`logits_to_text` function loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ta7xLtz_R4vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_model(input_shape, output_sequence_length, english_vocab_size, german_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a basic RNN on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param german_vocab_size: Number of unique german words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.005\n",
        "    \n",
        "    # TODO: Build the layers\n",
        "    model = Sequential()\n",
        "    model.add(GRU(256, input_shape=input_shape[1:], return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(Dense(german_vocab_size, activation='softmax'))) \n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Reshaping the input to work with a basic RNN\n",
        "tmp_x = pad(preproc_english_sentences, max_german_sequence_length)\n",
        "tmp_x = tmp_x.reshape((-1, preproc_german_sentences.shape[-2], 1))"
      ],
      "metadata": {
        "id": "NZbkW2M-SDtL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_rnn_model = simple_model(\n",
        "    tmp_x.shape,\n",
        "    max_german_sequence_length,\n",
        "    english_vocab_size,\n",
        "    german_vocab_size)\n",
        "\n",
        "print(simple_rnn_model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymACFHCDMemz",
        "outputId": "a8fbc953-3687-4a7c-dfca-023c7fe284a4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 91, 256)           198912    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 91, 1024)         263168    \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 91, 1024)          0         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 91, 5439)         5574975   \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,037,055\n",
            "Trainable params: 6,037,055\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "simple_rnn_model.fit(tmp_x, preproc_german_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXz693nrNQve",
        "outputId": "352a2263-412d-4e76-e0fb-75c8d4365272"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 9s 9s/step - loss: 8.6013 - accuracy: 0.3983 - val_loss: nan - val_accuracy: 0.6581\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.0222 - accuracy: 0.7815 - val_loss: nan - val_accuracy: 0.6581\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.0728 - accuracy: 0.7815 - val_loss: nan - val_accuracy: 0.6543\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.4841 - accuracy: 0.7611 - val_loss: nan - val_accuracy: 0.6581\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9821 - accuracy: 0.7814 - val_loss: nan - val_accuracy: 0.6581\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9451 - accuracy: 0.7815 - val_loss: nan - val_accuracy: 0.6585\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9497 - accuracy: 0.7804 - val_loss: nan - val_accuracy: 0.6588\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0033 - accuracy: 0.7761 - val_loss: nan - val_accuracy: 0.6588\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9651 - accuracy: 0.7758 - val_loss: nan - val_accuracy: 0.6584\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.8580 - accuracy: 0.7794 - val_loss: nan - val_accuracy: 0.6582\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5eb603b910>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print prediction(s)\n",
        "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], german_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkWt3RBjNSg8",
        "outputId": "c382ad0c-4766-4418-9b95-c05a3d834686"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_model(input_shape, output_sequence_length, english_vocab_size, german_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a RNN model using word embedding on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param german_vocab_size: Number of unique german words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "\n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.005\n",
        "    \n",
        "    # TODO: Build the layers\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(english_vocab_size, 256, input_length=input_shape[1], input_shape=input_shape[1:]))\n",
        "    model.add(GRU(256, return_sequences=True))    \n",
        "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(Dense(german_vocab_size, activation='softmax'))) \n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# TODO: Reshape the input\n",
        "tmp_x = pad(preproc_english_sentences, preproc_german_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_german_sentences.shape[-2]))\n",
        "\n",
        "# TODO: Train the neural network\n",
        "embed_rnn_model = embed_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_german_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(german_tokenizer.word_index)+1)\n",
        "\n",
        "embed_rnn_model.summary()\n",
        "\n",
        "embed_rnn_model.fit(tmp_x, preproc_german_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
        "\n",
        "# TODO: Print prediction(s)\n",
        "print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], german_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDB2i4iKOS6c",
        "outputId": "105c8016-729a-4bf8-e772-d9d47d425793"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 91, 256)           1070336   \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 91, 256)           394752    \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 91, 1024)         263168    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 91, 1024)          0         \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 91, 5440)         5576000   \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,304,256\n",
            "Trainable params: 7,304,256\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 8.6017 - accuracy: 2.7473e-05 - val_loss: 8.3623 - val_accuracy: 0.6581\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.3212 - accuracy: 0.7815 - val_loss: 6.3478 - val_accuracy: 0.6581\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.9400 - accuracy: 0.7815 - val_loss: 3.4022 - val_accuracy: 0.6581\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0458 - accuracy: 0.7815 - val_loss: 4.0756 - val_accuracy: 0.6581\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.3203 - accuracy: 0.7815 - val_loss: 3.4197 - val_accuracy: 0.6581\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9363 - accuracy: 0.7815 - val_loss: 3.0833 - val_accuracy: 0.6532\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.1565 - accuracy: 0.7804 - val_loss: 3.0817 - val_accuracy: 0.6497\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.1575 - accuracy: 0.7749 - val_loss: 2.9869 - val_accuracy: 0.6485\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0575 - accuracy: 0.7744 - val_loss: 2.8737 - val_accuracy: 0.6483\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9746 - accuracy: 0.7750 - val_loss: 2.8787 - val_accuracy: 0.6412\n",
            "at at at at at at at at at at at at at at at at at at at at at at at at at at at <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print(\"Prediction:\")\n",
        "print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], german_tokenizer))\n",
        "\n",
        "print(\"\\nCorrect Translation:\")\n",
        "print(german_sentences[:1])\n",
        "\n",
        "print(\"\\nOriginal text:\")\n",
        "print(english_sentences[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRXoE6cCRjol",
        "outputId": "deb86596-8983-4c58-c23c-6c02b8bf69c6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:\n",
            "at at at at at at at at at at at at at at at at at at at at at at at at at at at <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Correct Translation:\n",
            "['iron cement ist eine gebrauchs ##AT##-##AT## fertige Paste , die mit einem Spachtel oder den Fingern als Hohlkehle in die Formecken ( Winkel ) der Stahlguss -Kokille aufgetragen wird .\\n']\n",
            "\n",
            "Original text:\n",
            "['iron cement is a ready for use paste which is laid as a fillet by putty knife or finger in the mould edges ( corners ) of the steel ingot mould .\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bd_model(input_shape, output_sequence_length, english_vocab_size, german_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train a bidirectional RNN model on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param german_vocab_size: Number of unique german words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # TODO: Implement\n",
        "\n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.003\n",
        "    \n",
        "    # TODO: Build the layers\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(GRU(128, return_sequences=True), input_shape=input_shape[1:]))\n",
        "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(Dense(german_vocab_size, activation='softmax'))) \n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# TODO: Reshape the input\n",
        "tmp_x = pad(preproc_english_sentences, preproc_german_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_german_sentences.shape[-2]))\n",
        "\n",
        "# TODO: Train and Print prediction(s)\n",
        "embed_rnn_model = embed_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_german_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(german_tokenizer.word_index)+1)\n",
        "\n",
        "embed_rnn_model.summary()\n",
        "\n",
        "embed_rnn_model.fit(tmp_x, preproc_german_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
        "\n",
        "print(logits_to_text(embed_rnn_model.predict(tmp_x[:1])[0], german_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCf8_hPjRtEC",
        "outputId": "0743eb8a-e492-4859-ae17-7058967794c9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 91, 256)           1070336   \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 91, 256)           394752    \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 91, 1024)         263168    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 91, 1024)          0         \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 91, 5440)         5576000   \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,304,256\n",
            "Trainable params: 7,304,256\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 8.5991 - accuracy: 4.1209e-05 - val_loss: 8.3316 - val_accuracy: 0.6581\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.2849 - accuracy: 0.7815 - val_loss: 5.4164 - val_accuracy: 0.6581\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.8269 - accuracy: 0.7815 - val_loss: 4.0437 - val_accuracy: 0.6581\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.3224 - accuracy: 0.7815 - val_loss: 4.5995 - val_accuracy: 0.6581\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6447 - accuracy: 0.7815 - val_loss: 4.5427 - val_accuracy: 0.6581\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.5274 - accuracy: 0.7815 - val_loss: 3.6350 - val_accuracy: 0.6549\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.1038 - accuracy: 0.7702 - val_loss: 3.0554 - val_accuracy: 0.6364\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0755 - accuracy: 0.7650 - val_loss: 2.9996 - val_accuracy: 0.6427\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9390 - accuracy: 0.7757 - val_loss: 2.9874 - val_accuracy: 0.6515\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.8994 - accuracy: 0.7831 - val_loss: 2.8942 - val_accuracy: 0.6519\n",
            "e e e e e e <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cDBrbl5JR7B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encdec_model(input_shape, output_sequence_length, english_vocab_size, german_vocab_size):\n",
        "    \"\"\"\n",
        "    Build and train an encoder-decoder model on x and y\n",
        "    :param input_shape: Tuple of input shape\n",
        "    :param output_sequence_length: Length of output sequence\n",
        "    :param english_vocab_size: Number of unique English words in the dataset\n",
        "    :param german_vocab_size: Number of unique german words in the dataset\n",
        "    :return: Keras model built, but not trained\n",
        "    \"\"\"\n",
        "    # OPTIONAL: Implement\n",
        "    \n",
        "    # Hyperparameters\n",
        "    learning_rate = 0.001\n",
        "    \n",
        "    # Build the layers    \n",
        "    model = Sequential()\n",
        "    # Encoder\n",
        "    model.add(GRU(256, input_shape=input_shape[1:], go_backwards=True))\n",
        "    model.add(RepeatVector(output_sequence_length))\n",
        "    # Decoder\n",
        "    model.add(GRU(256, return_sequences=True))\n",
        "    model.add(TimeDistributed(Dense(1024, activation='relu')))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(TimeDistributed(Dense(german_vocab_size, activation='softmax')))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "# Reshape the input\n",
        "tmp_x = pad(preproc_english_sentences, preproc_german_sentences.shape[1])\n",
        "tmp_x = tmp_x.reshape((-1, preproc_german_sentences.shape[-2], 1))\n",
        "\n",
        "# Train and Print prediction(s)\n",
        "encdec_rnn_model = encdec_model(\n",
        "    tmp_x.shape,\n",
        "    preproc_german_sentences.shape[1],\n",
        "    len(english_tokenizer.word_index)+1,\n",
        "    len(german_tokenizer.word_index)+1)\n",
        "\n",
        "encdec_rnn_model.summary()\n",
        "\n",
        "encdec_rnn_model.fit(tmp_x, preproc_german_sentences, batch_size=1024, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQG53HYoR9AT",
        "outputId": "cf72b0b8-c6f1-431e-ca44-5c4403af2fe1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_3 (GRU)                 (None, 256)               198912    \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 91, 256)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " gru_4 (GRU)                 (None, 91, 256)           394752    \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDis  (None, 91, 1024)         263168    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 91, 1024)          0         \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 91, 5440)         5576000   \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,432,832\n",
            "Trainable params: 6,432,832\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 8.5996 - accuracy: 8.2418e-05 - val_loss: 7.6488 - val_accuracy: 0.6581\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.5496 - accuracy: 0.7815 - val_loss: 6.5353 - val_accuracy: 0.6581\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.2975 - accuracy: 0.7815 - val_loss: 5.0951 - val_accuracy: 0.6581\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.6468 - accuracy: 0.7815 - val_loss: 3.6136 - val_accuracy: 0.6581\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.8459 - accuracy: 0.7815 - val_loss: 3.3949 - val_accuracy: 0.6581\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.1608 - accuracy: 0.7815 - val_loss: 4.0051 - val_accuracy: 0.6581\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.4382 - accuracy: 0.7815 - val_loss: 4.4106 - val_accuracy: 0.6581\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6512 - accuracy: 0.7815 - val_loss: 4.4863 - val_accuracy: 0.6581\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7092 - accuracy: 0.7815 - val_loss: 4.4327 - val_accuracy: 0.6581\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6739 - accuracy: 0.7815 - val_loss: 4.3077 - val_accuracy: 0.6581\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e971a3290>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print prediction(s)\n",
        "print(\"Prediction:\")\n",
        "print(logits_to_text(encdec_rnn_model.predict(tmp_x[:1])[0], german_tokenizer))\n",
        "\n",
        "print(\"\\nCorrect Translation:\")\n",
        "print(german_sentences[:1])\n",
        "\n",
        "print(\"\\nOriginal text:\")\n",
        "print(english_sentences[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4gmQz5uSTPM",
        "outputId": "7201458c-95a4-42f6-c366-5d1c4c4bdda7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "\n",
            "Correct Translation:\n",
            "['iron cement ist eine gebrauchs ##AT##-##AT## fertige Paste , die mit einem Spachtel oder den Fingern als Hohlkehle in die Formecken ( Winkel ) der Stahlguss -Kokille aufgetragen wird .\\n']\n",
            "\n",
            "Original text:\n",
            "['iron cement is a ready for use paste which is laid as a fillet by putty knife or finger in the mould edges ( corners ) of the steel ingot mould .\\n']\n"
          ]
        }
      ]
    }
  ]
}